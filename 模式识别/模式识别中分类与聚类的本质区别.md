# 模式识别中分类与聚类的本质区别
` 2019年05月11日  -- 小k.o`

----------
 模式识别、机器学习中有两类的大问题，一个是**分类**，一个是**聚类**。 在我们的生活中，我们常常没有过多的去区分这两个概念，觉得聚类就是分类，分类也差不多就是聚类，下面，我们就具体来研究下分类与聚类之间在数据挖掘中本质的区别。

# 分类

分类有如下几种说法，但表达的意思是相同的。

- 分类（classification）:分类任务就是通过学习得到一个目标函数f，把每个属性集x映射到一个预先定义的类标号y中。

- 分类是根据一些给定的已知类别标号的样本，训练某种学习机器（即得到某种目标函数），使它能够对未知类别的样本进行分类。这属于supervised learning（监督学习）。

- 分类：通过学习来得到样本属性与类标号之间的关系。 
用自己的话来说，就是我们根据已知的一些样本（包括属性与类标号）来得到分类模型（即得到样本属性与类标号之间的函数），然后通过此目标函数来对只包含属性的样本数据进行分类。

# 分类算法的局限
分类作为一种监督学习方法，要求必须事先明确知道各个类别的信息，并且断言所有待分类项都有一个类别与之对应。但是很多时候上述条件得不到满足，尤其是在处理海量数据的时候，如果通过预处理使得数据满足分类算法的要求，则代价非常大，这时候可以考虑使用聚类算法。

# 聚类
聚类的相关的一些概念如下

- 而聚类指事先并不知道任何样本的类别标号，希望通过某种算法来把一组未知类别的样本划分成若干类别，聚类的时候，我们并不关心某一类是什么，我们需要实现的目标只是把相似的东西聚到一起，这在机器学习中被称作 unsupervised learning （无监督学习）


- 通常，人们根据样本间的某种距离或者相似性来定义聚类，即把相似的（或距离近的）样本聚为同一类，而把不相似的（或距离远的）样本归在其他类。


- 聚类的目标：组内的对象相互之间时相似的（相关的），而不同组中的对象是不同的（不相关的）。组内的相似性越大，组间差别越大，聚类就越好。

# 分类与聚类的比较

- 聚类分析是研究如何在没有训练的条件下把样本划分为若干类。


- 在分类中，对于目标数据库中存在哪些类是知道的，要做的就是将每一条记录分别属于哪一类标记出来。


- 聚类需要解决的问题是将已给定的若干无标记的模式聚集起来使之成为有意义的聚类，聚类是在预先不知道目标数据库到底有多少类的情况下，希望将所有的记录组成不同的类或者说聚类，并且使得在这种分类情况下，以某种度量（例如：距离）为标准的相似性，在同一聚类之间最小化，而在不同聚类之间最大化。


- 与分类不同，无监督学习不依赖预先定义的类或带类标记的训练实例，需要由聚类学习算法自动确定标记，而分类学习的实例或数据样本有类别标记。


# 要说明内容
因为最近在研究者两种算法，也就刚好用来说一下分类和聚类不同的算法。 
**SVM与二分K均值算法的区别之一：支持向量机（SVM）是一种分类算法，二分k均值算法属于一种聚类算法。**

在《数据挖掘导论（完整版）》这本书第306页中有这样一句话：聚类可以看做一种分类，它用类标号创建对象的标记，然而只能从数据导出这些标号。相比之下，前面所说的分类是监督分类（supervised classification）:即使用有类标号已知的对象开发的模型，对新的、无标记的对象赋予类标号。为此，有时称聚类分析为非监督分类（unsupervised classification）。在数据挖掘中，不附加任何条件使用术语分类时，通常是指监督分类。
聚类
聚类的相关的一些概念如下

而聚类指事先并不知道任何样本的类别标号，希望通过某种算法来把一组未知类别的样本划分成若干类别，聚类的时候，我们并不关心某一类是什么，我们需要实现的目标只是把相似的东西聚到一起，这在机器学习中被称作 unsupervised learning （无监督学习）
通常，人们根据样本间的某种距离或者相似性来定义聚类，即把相似的（或距离近的）样本聚为同一类，而把不相似的（或距离远的）样本归在其他类。
聚类的目标：组内的对象相互之间时相似的（相关的），而不同组中的对象是不同的（不相关的）。组内的相似性越大，组间差别越大，聚类就越好。
分类与聚类的比较
聚类分析是研究如何在没有训练的条件下把样本划分为若干类。
在分类中，对于目标数据库中存在哪些类是知道的，要做的就是将每一条记录分别属于哪一类标记出来。
聚类需要解决的问题是将已给定的若干无标记的模式聚集起来使之成为有意义的聚类，聚类是在预先不知道目标数据库到底有多少类的情况下，希望将所有的记录组成不同的类或者说聚类，并且使得在这种分类情况下，以某种度量（例如：距离）为标准的相似性，在同一聚类之间最小化，而在不同聚类之间最大化。
与分类不同，无监督学习不依赖预先定义的类或带类标记的训练实例，需要由聚类学习算法自动确定标记，而分类学习的实例或数据样本有类别标记。
要说明内容
因为最近在研究者两种算法，也就刚好用来说一下分类和聚类不同的算法。 
SVM与二分K均值算法的区别之一：支持向量机（SVM）是一种分类算法，二分k均值算法属于一种聚类算法。

在《数据挖掘导论（完整版）》这本书第306页中有这样一句话：聚类可以看做一种分类，它用类标号创建对象的标记，然而只能从数据导出这些标号。相比之下，前面所说的分类是监督分类（supervised classification）:即使用有类标号已知的对象开发的模型，对新的、无标记的对象赋予类标号。为此，有时称聚类分析为非监督分类（unsupervised classification）。在数据挖掘中，不附加任何条件使用术语分类时，通常是指监督分类。

**因此，SVM与二分K均值算法的区别之一：支持向量机（SVM）是一种监督分类算法，二分k均值算法属于一种非监督分类算法。**